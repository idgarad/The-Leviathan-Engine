# SeaweedFS S3-Compatible Backend Setup Guide (Terraform State Management)

## Tool Overview
SeaweedFS is a fast, distributed storage system for storing and serving billions of files. It provides S3-compatible object storage with excellent performance for both small and large files, making it ideal for Terraform state, game asset storage, and backup systems.

- **Role:** Provides high-performance S3 API storage for Terraform state, game assets, and distributed file storage
- **Key Features:** Simple architecture, high performance, automatic replication, S3 API compatibility
- **References:**
  - [SeaweedFS Official Documentation](https://github.com/seaweedfs/seaweedfs/wiki)
  - [SeaweedFS S3 Gateway](https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API)
  - [Terraform S3 Backend](https://developer.hashicorp.com/terraform/language/settings/backends/s3)
  - Book: "Infrastructure as Code" by Kief Morris (ISBN: 978-1098114671)
  - Book: "Terraform: Up & Running" by Yevgeniy Brikman (ISBN: 978-1098116743)
  - Academic Paper: "Finding a needle in Haystack: Facebook's photo storage" (Beaver et al., 2010)
    - Available: https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf
    - **Relevance**: SeaweedFS architecture inspired by Facebook's Haystack design

---

## Architecture Overview

SeaweedFS consists of three main components:

- **Master Server**: Manages file metadata, volume assignments, and cluster topology
- **Volume Server**: Stores actual file data in volumes (collections of files)
- **Filer**: Optional component providing POSIX-like filesystem interface and S3 API gateway

**For our use case (Terraform state + game assets):**
- 1+ Master servers (3+ for HA)
- 3+ Volume servers (for replication)
- 1+ Filer with S3 gateway enabled

---

## Step 1: Plan Deployment & Prerequisites

### Infrastructure Decisions
- **Deployment Model:** 
  - **Single-node development**: All components on one host
  - **Production cluster**: Separate master, volume, and filer servers
- **Host Selection:** 
  - LXC containers (lighter, requires proper privileges for file access)
  - VMs (full isolation, recommended for production)
- **Storage Requirements:**
  - Master: Minimal (metadata only), fast SSD recommended
  - Volume: Bulk storage, mount dedicated volumes for `/data`
  - Filer: Moderate (caching and metadata), SSD recommended
- **Networking:**
  - Master: TCP 9333 (HTTP API), 19333 (gRPC)
  - Volume: TCP 8080 (HTTP API), 18080 (gRPC)
  - Filer: TCP 8888 (HTTP/S3 API), 18888 (gRPC)
  - Segment network access to trusted clients only

### Prerequisites
```bash
# Required packages
sudo apt-get update
sudo apt-get install -y curl wget unzip

# Optional but recommended
sudo apt-get install -y htop iotop sysstat
```

---

## Step 2: Install SeaweedFS

### Download and Install Binary
```bash
# Get latest version (check https://github.com/seaweedfs/seaweedfs/releases)
export WEED_VERSION="3.60"  # Update to latest stable version

# Download for Linux AMD64
wget https://github.com/seaweedfs/seaweedfs/releases/download/${WEED_VERSION}/linux_amd64.tar.gz

# Extract and install
tar xzf linux_amd64.tar.gz
sudo install -o root -g root -m 0755 weed /usr/local/bin/weed
rm linux_amd64.tar.gz

# Verify installation
weed version
```

### Create System User and Directories
```bash
# Create dedicated user
sudo useradd -r -s /bin/false -d /var/lib/seaweedfs seaweedfs

# Create directory structure
sudo mkdir -p /etc/seaweedfs
sudo mkdir -p /var/lib/seaweedfs/{master,volume,filer}
sudo mkdir -p /var/log/seaweedfs

# Set permissions
sudo chown -R seaweedfs:seaweedfs /var/lib/seaweedfs
sudo chown -R seaweedfs:seaweedfs /var/log/seaweedfs
sudo chown -R seaweedfs:seaweedfs /etc/seaweedfs
```

---

## Step 3: Configure Master Server

### Create Master Configuration
Create `/etc/seaweedfs/master.toml`:

```toml
# Master server manages file metadata and volume assignments
# For production, run 3+ masters with raft consensus

[master]
# Listen address for HTTP API
port = 9333
# Metadata directory
dir = "/var/lib/seaweedfs/master"
# Volume size limit (default 30GB per volume)
volumeSizeLimitMB = 30000
# Pulse interval for volume heartbeats (seconds)
pulseSeconds = 5

# For clustered setup (3+ masters)
# peers = "master1:9333,master2:9333,master3:9333"

[master.maintenance]
# Script to run for maintenance tasks
# scripts = "/etc/seaweedfs/maintenance.sh"
```

### Create Systemd Service
Create `/etc/systemd/system/seaweedfs-master.service`:

```ini
[Unit]
Description=SeaweedFS Master Server
Documentation=https://github.com/seaweedfs/seaweedfs/wiki
After=network.target

[Service]
Type=simple
User=seaweedfs
Group=seaweedfs
ExecStart=/usr/local/bin/weed master \
    -port=9333 \
    -dir=/var/lib/seaweedfs/master \
    -volumeSizeLimitMB=30000 \
    -defaultReplication=001
Restart=on-failure
RestartSec=5
StandardOutput=append:/var/log/seaweedfs/master.log
StandardError=append:/var/log/seaweedfs/master-error.log

# Security hardening
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/lib/seaweedfs/master /var/log/seaweedfs

[Install]
WantedBy=multi-user.target
```

---

## Step 4: Configure Volume Servers

### Create Volume Configuration
Create `/etc/seaweedfs/volume.toml`:

```toml
# Volume servers store actual file data

[volume]
# Listen port
port = 8080
# Data directory (mount dedicated storage here)
dir = "/var/lib/seaweedfs/volume"
# Maximum volumes per server
max = 100
# Master server address
mserver = "localhost:9333"
# Replication type (000=no replication, 001=1 replica, 010=rack replica)
defaultReplication = "001"
# Rack identifier for topology-aware replication
# rack = "rack1"
# Data center identifier
# dataCenter = "dc1"
```

### Create Systemd Service
Create `/etc/systemd/system/seaweedfs-volume.service`:

```ini
[Unit]
Description=SeaweedFS Volume Server
Documentation=https://github.com/seaweedfs/seaweedfs/wiki
After=network.target seaweedfs-master.service
Requires=seaweedfs-master.service

[Service]
Type=simple
User=seaweedfs
Group=seaweedfs
ExecStart=/usr/local/bin/weed volume \
    -port=8080 \
    -dir=/var/lib/seaweedfs/volume \
    -max=100 \
    -mserver=localhost:9333 \
    -dataCenter=dc1 \
    -rack=rack1
Restart=on-failure
RestartSec=5
StandardOutput=append:/var/log/seaweedfs/volume.log
StandardError=append:/var/log/seaweedfs/volume-error.log

# Security hardening
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/lib/seaweedfs/volume /var/log/seaweedfs

[Install]
WantedBy=multi-user.target
```

---

## Step 5: Configure Filer with S3 Gateway

### Create Filer Configuration
Create `/etc/seaweedfs/filer.toml`:

```toml
# Filer provides filesystem and S3 API interfaces

[filer]
# Listen port
port = 8888
# Master server address
master = "localhost:9333"
# Metadata storage (leveldb2 recommended for production)
# Options: leveldb2, leveldb3, postgres, mysql, redis
defaultLevelDbDirectory = "/var/lib/seaweedfs/filer/leveldb"

[filer.options]
# Enable recursive directory listing
recursive_delete = true
# Metadata cache size (MB)
dir_listing_cache_expiration_minutes = 5

# S3 API Configuration
[s3]
enabled = true
port = 8333
# Domain for virtual-host-style requests (optional)
# domainName = "s3.example.com"
# Allow anonymous read (set false for security)
allowEmptyFolder = false
```

### Create Systemd Service
Create `/etc/systemd/system/seaweedfs-filer.service`:

```ini
[Unit]
Description=SeaweedFS Filer Server (S3 Gateway)
Documentation=https://github.com/seaweedfs/seaweedfs/wiki
After=network.target seaweedfs-master.service seaweedfs-volume.service
Requires=seaweedfs-master.service seaweedfs-volume.service

[Service]
Type=simple
User=seaweedfs
Group=seaweedfs
ExecStart=/usr/local/bin/weed filer \
    -port=8888 \
    -master=localhost:9333 \
    -s3 \
    -s3.port=8333 \
    -defaultReplicaPlacement=001
Restart=on-failure
RestartSec=5
StandardOutput=append:/var/log/seaweedfs/filer.log
StandardError=append:/var/log/seaweedfs/filer-error.log

# Security hardening
NoNewPrivileges=true
PrivateTmp=true
ProtectSystem=strict
ProtectHome=true
ReadWritePaths=/var/lib/seaweedfs/filer /var/log/seaweedfs

[Install]
WantedBy=multi-user.target
```

---

## Step 6: Start Services and Verify

### Enable and Start Services
```bash
# Reload systemd
sudo systemctl daemon-reload

# Enable services to start on boot
sudo systemctl enable seaweedfs-master seaweedfs-volume seaweedfs-filer

# Start services in order
sudo systemctl start seaweedfs-master
sleep 5  # Wait for master to initialize
sudo systemctl start seaweedfs-volume
sleep 5  # Wait for volume to register
sudo systemctl start seaweedfs-filer

# Check status
sudo systemctl status seaweedfs-master
sudo systemctl status seaweedfs-volume
sudo systemctl status seaweedfs-filer

# View logs if needed
sudo journalctl -u seaweedfs-master -f
```

### Verify Cluster Health
```bash
# Check master status
curl http://localhost:9333/cluster/status

# Check volume server
curl http://localhost:8080/status

# Check filer
curl http://localhost:8888/

# Test S3 API endpoint
curl http://localhost:8333/
```

---

## Step 7: Configure S3 Access (AWS CLI Compatible)

### Install and Configure AWS CLI
```bash
# Install AWS CLI
sudo apt-get install -y awscli

# Configure for SeaweedFS
aws configure set aws_access_key_id admin
aws configure set aws_secret_access_key admin_password
aws configure set default.region us-east-1
aws configure set default.s3.signature_version s3v4
```

### Create S3 Configuration File
Create `~/.aws/config`:

```ini
[default]
region = us-east-1
output = json

[profile seaweedfs]
region = us-east-1
s3 =
    endpoint_url = http://localhost:8333
    signature_version = s3v4
```

### Test S3 Operations
```bash
# Create bucket for Terraform state
aws --endpoint-url=http://localhost:8333 s3 mb s3://terraform-state

# List buckets
aws --endpoint-url=http://localhost:8333 s3 ls

# Upload test file
echo "test" > test.txt
aws --endpoint-url=http://localhost:8333 s3 cp test.txt s3://terraform-state/

# List bucket contents
aws --endpoint-url=http://localhost:8333 s3 ls s3://terraform-state/

# Download test file
aws --endpoint-url=http://localhost:8333 s3 cp s3://terraform-state/test.txt test-download.txt

# Cleanup
rm test.txt test-download.txt
```

---

## Step 8: Configure Terraform Backend

### Create Terraform Backend Configuration
Create `backend.tf` in your Terraform project:

```hcl
terraform {
  backend "s3" {
    bucket = "terraform-state"
    key    = "leviathan-engine/terraform.tfstate"
    region = "us-east-1"
    
    # SeaweedFS endpoint
    endpoint = "http://seaweedfs.local:8333"
    
    # Disable AWS-specific features
    skip_credentials_validation = true
    skip_metadata_api_check     = true
    skip_region_validation      = true
    force_path_style           = true
    
    # Credentials (use environment variables in production)
    access_key = "admin"
    secret_key = "admin_password"
  }
}
```

### Initialize Terraform
```bash
# Initialize backend
terraform init

# Verify state storage
aws --endpoint-url=http://localhost:8333 s3 ls s3://terraform-state/leviathan-engine/
```

---

## Step 9: Security Hardening

### Enable Authentication (Production)
SeaweedFS S3 authentication can be configured with JWT tokens or IAM-style credentials.

Create `/etc/seaweedfs/security.toml`:

```toml
[jwt.signing]
# Generate secure secret: openssl rand -base64 32
key = "YOUR_SECURE_JWT_SECRET_HERE"

[jwt.signing.read]
expiresAfterSeconds = 3600

[jwt.signing.write]
expiresAfterSeconds = 3600
```

### Configure Firewall Rules
```bash
# Allow only trusted networks to access SeaweedFS
sudo ufw allow from 192.168.1.0/24 to any port 9333 proto tcp comment 'SeaweedFS Master'
sudo ufw allow from 192.168.1.0/24 to any port 8080 proto tcp comment 'SeaweedFS Volume'
sudo ufw allow from 192.168.1.0/24 to any port 8333 proto tcp comment 'SeaweedFS S3'
sudo ufw enable
```

### Set Up HTTPS (Production)
```bash
# Install certbot for Let's Encrypt certificates
sudo apt-get install -y certbot

# Generate certificates
sudo certbot certonly --standalone -d s3.yourdomain.com

# Configure filer to use HTTPS
# Add to systemd service:
# -s3.cert.file=/etc/letsencrypt/live/s3.yourdomain.com/fullchain.pem \
# -s3.key.file=/etc/letsencrypt/live/s3.yourdomain.com/privkey.pem
```

---

## Step 10: Monitoring and Maintenance

### Prometheus Metrics
SeaweedFS exposes Prometheus metrics on each component:

```yaml
# Add to Prometheus configuration
scrape_configs:
  - job_name: 'seaweedfs-master'
    static_configs:
      - targets: ['localhost:9333']
  
  - job_name: 'seaweedfs-volume'
    static_configs:
      - targets: ['localhost:8080']
  
  - job_name: 'seaweedfs-filer'
    static_configs:
      - targets: ['localhost:8888']
```

### Health Check Scripts
Create `/usr/local/bin/seaweedfs-health-check.sh`:

```bash
#!/bin/bash
set -e

# Check master
if ! curl -sf http://localhost:9333/cluster/status > /dev/null; then
    echo "Master server unhealthy"
    exit 1
fi

# Check volume
if ! curl -sf http://localhost:8080/status > /dev/null; then
    echo "Volume server unhealthy"
    exit 1
fi

# Check filer/S3
if ! curl -sf http://localhost:8333/ > /dev/null; then
    echo "Filer/S3 gateway unhealthy"
    exit 1
fi

echo "All SeaweedFS services healthy"
exit 0
```

### Backup Strategies
```bash
# Backup master metadata (critical)
sudo tar czf /backup/seaweedfs-master-$(date +%Y%m%d).tar.gz \
    /var/lib/seaweedfs/master/

# Volume data is self-replicating, but consider:
# - Regular snapshots of volume directories
# - Offsite replication for disaster recovery
# - Periodic verification of replica consistency
```

### Log Rotation
Create `/etc/logrotate.d/seaweedfs`:

```
/var/log/seaweedfs/*.log {
    daily
    rotate 14
    compress
    delaycompress
    missingok
    notifempty
    create 0640 seaweedfs seaweedfs
    sharedscripts
    postrotate
        systemctl reload seaweedfs-master seaweedfs-volume seaweedfs-filer > /dev/null 2>&1 || true
    endscript
}
```

---

## Production Considerations

### High Availability Setup
For production deployments, run:

- **3+ Master Servers** (raft consensus for metadata)
- **6+ Volume Servers** (minimum for 001 replication across 3 racks)
- **2+ Filer Servers** (behind load balancer for S3 API)

### Topology-Aware Replication
Configure data centers and racks for intelligent replica placement:

```bash
# Volume server with topology info
weed volume \
    -dataCenter=dc1 \
    -rack=rack1 \
    -mserver=master1:9333,master2:9333,master3:9333
```

Replication codes:
- `000` = No replication
- `001` = 1 replica on different volume server
- `010` = 1 replica on different rack
- `100` = 1 replica on different data center

### Performance Tuning
```bash
# Increase file descriptor limits
echo "seaweedfs soft nofile 65536" | sudo tee -a /etc/security/limits.conf
echo "seaweedfs hard nofile 65536" | sudo tee -a /etc/security/limits.conf

# Enable BBR congestion control (Linux 4.9+)
echo "net.core.default_qdisc=fq" | sudo tee -a /etc/sysctl.conf
echo "net.ipv4.tcp_congestion_control=bbr" | sudo tee -a /etc/sysctl.conf
sudo sysctl -p

# Mount volumes with optimal settings
# Add to /etc/fstab:
# /dev/sdX /var/lib/seaweedfs/volume ext4 noatime,nodiratime 0 2
```

---

## Troubleshooting

### Common Issues

**Master server won't start:**
```bash
# Check logs
sudo journalctl -u seaweedfs-master -n 50

# Verify directory permissions
sudo ls -la /var/lib/seaweedfs/master/

# Check port conflicts
sudo netstat -tulpn | grep 9333
```

**Volume server not registering:**
```bash
# Verify master connectivity
curl http://localhost:9333/cluster/status

# Check volume server logs
sudo journalctl -u seaweedfs-volume -n 50

# Verify directory has space
df -h /var/lib/seaweedfs/volume/
```

**S3 operations failing:**
```bash
# Test filer connectivity
curl http://localhost:8888/

# Test S3 endpoint
curl http://localhost:8333/

# Check authentication
aws --endpoint-url=http://localhost:8333 --debug s3 ls
```

**Performance issues:**
```bash
# Check disk I/O
sudo iotop -o

# Check system resources
htop

# Review SeaweedFS metrics
curl http://localhost:9333/metrics
```

---

## Additional Resources

### Documentation
- [SeaweedFS Wiki](https://github.com/seaweedfs/seaweedfs/wiki)
- [S3 API Compatibility](https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API)
- [Architecture Overview](https://github.com/seaweedfs/seaweedfs/wiki/Architecture)

### Books
- **"Designing Data-Intensive Applications"** by Martin Kleppmann (ISBN: 978-1449373320)
  - Chapters 3 & 10: Storage systems and batch processing
- **"Infrastructure as Code"** by Kief Morris (ISBN: 978-1098114671)
- **"Site Reliability Engineering"** by Google (ISBN: 978-1491929124)
  - Free online: https://sre.google/books/

### Academic Papers
- **"The Google File System"** (Ghemawat et al., 2003)
  - Available: https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf
- **"Finding a needle in Haystack: Facebook's photo storage"** (Beaver et al., 2010)
  - Available: https://www.usenix.org/legacy/event/osdi10/tech/full_papers/Beaver.pdf

### Videos
- **"SeaweedFS Introduction"** by Chris Lu (creator)
- **"Distributed Storage Systems Explained"** series

---

## Next Steps

After SeaweedFS is operational:
1. **[03 - Terraform Setup](03-terraform-setup.md)** - Configure infrastructure as code
2. **[05 - Monitoring & Testing](05-monitoring-testing.md)** - Set up observability
3. Review game asset storage strategies for The Leviathan Engine

---

_Last updated: November 2025. Verify latest SeaweedFS version and security best practices before deployment._
